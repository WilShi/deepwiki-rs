use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use std::sync::Arc;
use std::sync::atomic::{AtomicU64, AtomicUsize, Ordering};
use std::time::Duration;

use crate::llm::client::types::TokenUsage;

/// ç¼“å­˜æ€§èƒ½ç›‘æ§å™¨
#[derive(Clone)]
pub struct CachePerformanceMonitor {
    metrics: Arc<CacheMetrics>,
}

/// ç¼“å­˜æŒ‡æ ‡
#[derive(Default)]
pub struct CacheMetrics {
    /// ç¼“å­˜å‘½ä¸­æ¬¡æ•°
    pub cache_hits: AtomicUsize,
    /// ç¼“å­˜æœªå‘½ä¸­æ¬¡æ•°
    pub cache_misses: AtomicUsize,
    /// ç¼“å­˜å†™å…¥æ¬¡æ•°
    pub cache_writes: AtomicUsize,
    /// ç¼“å­˜é”™è¯¯æ¬¡æ•°
    pub cache_errors: AtomicUsize,
    /// æ€»èŠ‚çœçš„æ¨ç†æ—¶é—´ï¼ˆç§’ï¼‰
    pub total_inference_time_saved: AtomicU64,
    /// æ€»èŠ‚çœçš„æ¨ç†æˆæœ¬ï¼ˆä¼°ç®—ï¼‰
    pub total_cost_saved: AtomicUsize,
    /// æ€»èŠ‚çœçš„è¾“å…¥tokenæ•°é‡
    pub total_input_tokens_saved: AtomicUsize,
    /// æ€»èŠ‚çœçš„è¾“å‡ºtokenæ•°é‡
    pub total_output_tokens_saved: AtomicUsize,
    /// åˆ†ç±»ç»Ÿè®¡æ•°æ®
    pub category_metrics: std::sync::RwLock<HashMap<String, CategoryMetrics>>,
}

/// åˆ†ç±»æŒ‡æ ‡æ•°æ®
#[derive(Default)]
pub struct CategoryMetrics {
    pub hits: AtomicU64,
    pub misses: AtomicU64,
    pub time_saved: AtomicU64,
}

/// ç¼“å­˜æ€§èƒ½æŠ¥å‘Š
#[derive(Debug, Serialize, Deserialize)]
#[allow(dead_code)] // é¢„ç•™åŠŸèƒ½ï¼Œå°šæœªä½¿ç”¨
pub struct CachePerformanceReport {
    /// ç¼“å­˜å‘½ä¸­ç‡
    pub hit_rate: f64,
    /// æ€»ç¼“å­˜æ“ä½œæ¬¡æ•°
    pub total_operations: usize,
    /// ç¼“å­˜å‘½ä¸­æ¬¡æ•°
    pub cache_hits: usize,
    /// ç¼“å­˜æœªå‘½ä¸­æ¬¡æ•°
    pub cache_misses: usize,
    /// ç¼“å­˜å†™å…¥æ¬¡æ•°
    pub cache_writes: usize,
    /// ç¼“å­˜é”™è¯¯æ¬¡æ•°
    pub cache_errors: usize,
    /// èŠ‚çœçš„æ¨ç†æ—¶é—´ï¼ˆç§’ï¼‰
    pub inference_time_saved: f64,
    /// èŠ‚çœçš„æ¨ç†æˆæœ¬ï¼ˆç¾å…ƒï¼Œä¼°ç®—ï¼‰
    pub cost_saved: f64,
    /// æ€§èƒ½æå‡ç™¾åˆ†æ¯”
    pub performance_improvement: f64,
    /// èŠ‚çœçš„è¾“å…¥tokenæ•°é‡
    pub input_tokens_saved: usize,
    /// èŠ‚çœçš„è¾“å‡ºtokenæ•°é‡
    pub output_tokens_saved: usize,
    /// åˆ†ç±»ç»Ÿè®¡
    pub category_stats: HashMap<String, CategoryPerformanceStats>,
}

/// åˆ†ç±»æ€§èƒ½ç»Ÿè®¡
#[derive(Debug, Serialize, Deserialize)]
#[allow(dead_code)] // é¢„ç•™åŠŸèƒ½ï¼Œå°šæœªä½¿ç”¨
pub struct CategoryPerformanceStats {
    pub hits: u64,
    pub misses: u64,
    pub hit_rate: f64,
    pub time_saved: f64,
    pub cost_saved: f64,
}

impl CachePerformanceMonitor {
    pub fn new() -> Self {
        Self {
            metrics: Arc::new(CacheMetrics::default()),
        }
    }

    /// è®°å½•ç¼“å­˜å‘½ä¸­
    pub fn record_cache_hit(
        &self,
        category: &str,
        inference_time_saved: Duration,
        token_usage: TokenUsage,
        model_name: &str,
    ) {
        self.metrics.cache_hits.fetch_add(1, Ordering::Relaxed);
        self.metrics
            .total_inference_time_saved
            .fetch_add(inference_time_saved.as_millis() as u64, Ordering::Relaxed);

        // è®°å½•èŠ‚çœçš„tokenæ•°é‡
        self.metrics
            .total_input_tokens_saved
            .fetch_add(token_usage.input_tokens, Ordering::Relaxed);
        self.metrics
            .total_output_tokens_saved
            .fetch_add(token_usage.output_tokens, Ordering::Relaxed);

        // åŸºäºå®é™…tokenä½¿ç”¨æƒ…å†µè®¡ç®—èŠ‚çœçš„æˆæœ¬
        let estimated_cost_saved = token_usage.estimate_cost(model_name);
        self.metrics.total_cost_saved.fetch_add(
            (estimated_cost_saved * 1000.0) as usize, // å­˜å‚¨ä¸ºæ¯«ç¾å…ƒ
            Ordering::Relaxed,
        );

        // æ›´æ–°åˆ†ç±»ç»Ÿè®¡
        if let Ok(mut category_map) = self.metrics.category_metrics.write() {
            let category_metrics = category_map.entry(category.to_string()).or_default();
            category_metrics.hits.fetch_add(1, Ordering::Relaxed);
            category_metrics.time_saved.fetch_add(inference_time_saved.as_millis() as u64, Ordering::Relaxed);
        }

        println!(
            "   ğŸ’° ç¼“å­˜å‘½ä¸­ [{}] - èŠ‚çœæ¨ç†æ—¶é—´: {:.2}ç§’, èŠ‚çœtokens: {}è¾“å…¥+{}è¾“å‡º, ä¼°ç®—èŠ‚çœæˆæœ¬: ${:.4}",
            category,
            inference_time_saved.as_secs_f64(),
            token_usage.input_tokens,
            token_usage.output_tokens,
            estimated_cost_saved
        );
    }

    /// è®°å½•ç¼“å­˜æœªå‘½ä¸­
    pub fn record_cache_miss(&self, category: &str) {
        self.metrics.cache_misses.fetch_add(1, Ordering::Relaxed);
        
        // æ›´æ–°åˆ†ç±»ç»Ÿè®¡
        if let Ok(mut category_map) = self.metrics.category_metrics.write() {
            let category_metrics = category_map.entry(category.to_string()).or_default();
            category_metrics.misses.fetch_add(1, Ordering::Relaxed);
        }
        
        println!("   âŒ› ç¼“å­˜æœªå‘½ä¸­ [{}] - éœ€è¦è¿›è¡ŒAIæ¨ç†", category);
    }

    /// è®°å½•ç¼“å­˜å†™å…¥
    pub fn record_cache_write(&self, category: &str) {
        self.metrics.cache_writes.fetch_add(1, Ordering::Relaxed);
        println!("   ğŸ’¾ ç¼“å­˜å†™å…¥ [{}] - ç»“æœå·²ç¼“å­˜", category);
    }

    /// è®°å½•ç¼“å­˜é”™è¯¯
    pub fn record_cache_error(&self, category: &str, error: &str) {
        self.metrics.cache_errors.fetch_add(1, Ordering::Relaxed);
        eprintln!("   âŒ ç¼“å­˜é”™è¯¯ [{}]: {}", category, error);
    }

    /// ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š
    #[allow(dead_code)] // é¢„ç•™åŠŸèƒ½ï¼Œå°šæœªä½¿ç”¨
    pub fn generate_report(&self) -> CachePerformanceReport {
        let hits = self.metrics.cache_hits.load(Ordering::Relaxed);
        let misses = self.metrics.cache_misses.load(Ordering::Relaxed);
        let writes = self.metrics.cache_writes.load(Ordering::Relaxed);
        let errors = self.metrics.cache_errors.load(Ordering::Relaxed);
        let total_operations = hits + misses;

        let hit_rate = if total_operations > 0 {
            hits as f64 / total_operations as f64
        } else {
            0.0
        };

        let inference_time_saved = self
            .metrics
            .total_inference_time_saved
            .load(Ordering::Relaxed) as f64
            / 1000.0; // è½¬æ¢ä¸ºç§’
        let cost_saved = self.metrics.total_cost_saved.load(Ordering::Relaxed) as f64 / 1000.0; // è½¬æ¢ä¸ºç¾å…ƒ

        let input_tokens_saved = self
            .metrics
            .total_input_tokens_saved
            .load(Ordering::Relaxed);
        let output_tokens_saved = self
            .metrics
            .total_output_tokens_saved
            .load(Ordering::Relaxed);

        let performance_improvement = if misses > 0 {
            (hits as f64 / (hits + misses) as f64) * 100.0
        } else {
            0.0
        };

        // ç”Ÿæˆåˆ†ç±»ç»Ÿè®¡
        let category_stats = if let Ok(category_map) = self.metrics.category_metrics.read() {
            category_map.iter().map(|(category, metrics)| {
                let cat_hits = metrics.hits.load(Ordering::Relaxed);
                let cat_misses = metrics.misses.load(Ordering::Relaxed);
                let cat_time_saved = metrics.time_saved.load(Ordering::Relaxed);
                
                let cat_hit_rate = if cat_hits + cat_misses > 0 {
                    cat_hits as f64 / (cat_hits + cat_misses) as f64
                } else {
                    0.0
                };
                
                let cat_time_saved_seconds = cat_time_saved as f64 / 1000.0;
                let cat_cost_saved = cat_time_saved_seconds * 0.00001; // ç®€åŒ–çš„æˆæœ¬ä¼°ç®—
                
                (category.clone(), CategoryPerformanceStats {
                    hits: cat_hits,
                    misses: cat_misses,
                    hit_rate: cat_hit_rate,
                    time_saved: cat_time_saved_seconds,
                    cost_saved: cat_cost_saved,
                })
            }).collect()
        } else {
            HashMap::new()
        };

        CachePerformanceReport {
            hit_rate,
            total_operations,
            cache_hits: hits,
            cache_misses: misses,
            cache_writes: writes,
            cache_errors: errors,
            inference_time_saved,
            cost_saved,
            performance_improvement,
            input_tokens_saved,
            output_tokens_saved,
            category_stats,
        }
    }
}

impl Default for CachePerformanceMonitor {
    fn default() -> Self {
        Self::new()
    }
}
