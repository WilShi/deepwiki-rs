//! LLMå®¢æˆ·ç«¯ - æä¾›ç»Ÿä¸€çš„LLMæœåŠ¡æ¥å£

use anyhow::Result;
use schemars::JsonSchema;
use serde::{Deserialize, Serialize};
use std::future::Future;

use crate::{config::Config, llm::client::utils::evaluate_befitting_model};

mod agent_builder;
mod providers;
mod react;
mod react_executor;
mod summary_reasoner;
pub mod types;
pub mod utils;

pub use react::{ReActConfig, ReActResponse};

use agent_builder::AgentBuilder;
use providers::ProviderClient;
use react_executor::ReActExecutor;
use summary_reasoner::SummaryReasoner;

/// LLMå®¢æˆ·ç«¯ - æä¾›ç»Ÿä¸€çš„LLMæœåŠ¡æ¥å£
#[derive(Clone)]
pub struct LLMClient {
    config: Config,
    client: ProviderClient,
}

impl LLMClient {
    /// åˆ›å»ºæ–°çš„LLMå®¢æˆ·ç«¯
    pub fn new(config: Config) -> Result<Self> {
        let client = ProviderClient::new(&config.llm)?;
        Ok(Self { client, config })
    }

    /// æ£€æŸ¥æ¨¡å‹è¿æ¥å’ŒåŠŸèƒ½æ˜¯å¦æ­£å¸¸
    pub async fn check_connection(&self) -> Result<()> {
        println!("ğŸ”„ æ­£åœ¨æ£€æŸ¥æ¨¡å‹è¿æ¥...");
        // ä½¿ç”¨ä¸€ä¸ªç®€å•çš„promptæ¥æµ‹è¯•è¿æ¥
        match self.prompt_without_react("System: You are a helpful assistant.", "Hello").await {
            Ok(_) => {
                println!("âœ… æ¨¡å‹è¿æ¥æ­£å¸¸");
                Ok(())
            }
            Err(e) => {
                eprintln!("âŒ æ¨¡å‹è¿æ¥å¤±è´¥: {}", e);
                Err(e)
            }
        }
    }

    /// è·å–Agentæ„å»ºå™¨
    fn get_agent_builder(&self) -> AgentBuilder<'_> {
        AgentBuilder::new(&self.client, &self.config)
    }

    /// é€šç”¨é‡è¯•é€»è¾‘ï¼Œç”¨äºå¤„ç†å¼‚æ­¥æ“ä½œçš„é‡è¯•æœºåˆ¶
    async fn retry_with_backoff<T, F, Fut>(&self, operation: F) -> Result<T>
    where
        F: Fn() -> Fut,
        Fut: Future<Output = Result<T, anyhow::Error>>,
    {
        let llm_config = &self.config.llm;
        let max_retries = llm_config.retry_attempts;
        let retry_delay_ms = llm_config.retry_delay_ms;
        let mut retries = 0;

        loop {
            match operation().await {
                Ok(result) => return Ok(result),
                Err(err) => {
                    retries += 1;
                    eprintln!(
                        "âŒ è°ƒç”¨æ¨¡å‹æœåŠ¡å‡ºé”™ï¼Œé‡è¯•ä¸­ (ç¬¬ {} / {}æ¬¡å°è¯•): {}",
                        retries, max_retries, err
                    );
                    if retries >= max_retries {
                        return Err(err);
                    }
                    tokio::time::sleep(std::time::Duration::from_millis(retry_delay_ms)).await;
                }
            }
        }
    }

    /// æ•°æ®æå–æ–¹æ³•
    pub async fn extract<T>(&self, system_prompt: &str, user_prompt: &str) -> Result<T>
    where
        T: JsonSchema + for<'a> Deserialize<'a> + Serialize + Send + Sync + 'static,
    {
        let (befitting_model, fallover_model) =
            evaluate_befitting_model(&self.config.llm, system_prompt, user_prompt);

        self.extract_inner(system_prompt, user_prompt, befitting_model, fallover_model)
            .await
    }

    async fn extract_inner<T>(
        &self,
        system_prompt: &str,
        user_prompt: &str,
        befitting_model: String,
        fallover_model: Option<String>,
    ) -> Result<T>
    where
        T: JsonSchema + for<'a> Deserialize<'a> + Serialize + Send + Sync + 'static,
    {
        let llm_config = &self.config.llm;

        let extractor =
            self.client
                .create_extractor::<T>(&befitting_model, system_prompt, llm_config);

        self.retry_with_backoff(|| async {
            match extractor.extract(user_prompt).await {
                Ok(r) => Ok(r),
                Err(e) => match fallover_model {
                    Some(ref model) => {
                        eprintln!(
                            "âŒ è°ƒç”¨æ¨¡å‹æœåŠ¡å‡ºé”™ï¼Œå°è¯• {} æ¬¡å‡å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨å¤‡é€‰æ¨¡å‹{}...{}",
                            llm_config.retry_attempts, model, e
                        );
                        let user_prompt_with_fixer = format!("{}\n\n**æ³¨æ„äº‹é¡¹**æ­¤å‰æˆ‘è°ƒç”¨å¤§æ¨¡å‹è¿‡ç¨‹æ—¶å­˜åœ¨é”™è¯¯ï¼Œé”™è¯¯ä¿¡æ¯ä¸ºâ€œ{}â€ï¼Œä½ æ³¨æ„ä½ è¿™ä¸€æ¬¡è¦è§„é¿è¿™ä¸ªé”™è¯¯", user_prompt, e);
                        Box::pin(self.extract_inner(
                            system_prompt,
                            &user_prompt_with_fixer,
                            model.clone(),
                            None,
                        ))
                        .await
                    }
                    None => {
                        eprintln!(
                            "âŒ è°ƒç”¨æ¨¡å‹æœåŠ¡å‡ºé”™ï¼Œå°è¯• {} æ¬¡å‡å¤±è´¥...{}",
                            llm_config.retry_attempts, e
                        );
                        Err(e)
                    }
                },
            }
        })
        .await
    }

    /// æ™ºèƒ½å¯¹è¯æ–¹æ³•ï¼ˆä½¿ç”¨é»˜è®¤ReActé…ç½®ï¼‰
    pub async fn prompt(&self, system_prompt: &str, user_prompt: &str) -> Result<String> {
        let react_config = ReActConfig::default();
        let response = self
            .prompt_with_react(system_prompt, user_prompt, react_config)
            .await?;
        Ok(response.content)
    }

    /// ä½¿ç”¨ReActæ¨¡å¼è¿›è¡Œå¤šè½®å¯¹è¯
    pub async fn prompt_with_react(
        &self,
        system_prompt: &str,
        user_prompt: &str,
        react_config: ReActConfig,
    ) -> Result<ReActResponse> {
        let agent_builder = self.get_agent_builder();
        let agent = agent_builder.build_agent_with_tools(system_prompt);

        let response = self
            .retry_with_backoff(|| async {
                ReActExecutor::execute(&agent, user_prompt, &react_config).await
            })
            .await?;

        // å¦‚æœè¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°ä¸”å¯ç”¨äº†æ€»ç»“æ¨ç†ï¼Œåˆ™å°è¯•fallover
        if response.stopped_by_max_depth
            && react_config.enable_summary_reasoning
            && response.chat_history.is_some()
        {
            if react_config.verbose {
                println!("ğŸ”„ å¯åŠ¨ReAct Agentæ€»ç»“è½¬ç›´æ¥æ¨ç†æ¨¡å¼...");
            }

            match self
                .try_summary_reasoning(system_prompt, user_prompt, &response)
                .await
            {
                Ok(summary_response) => {
                    if react_config.verbose {
                        println!("âœ… æ€»ç»“æ¨ç†å®Œæˆ");
                    }
                    return Ok(summary_response);
                }
                Err(e) => {
                    if react_config.verbose {
                        println!("âš ï¸  æ€»ç»“æ¨ç†å¤±è´¥ï¼Œè¿”å›åŸå§‹éƒ¨åˆ†ç»“æœ...{}", e);
                    }
                    // æ€»ç»“æ¨ç†å¤±è´¥æ—¶ï¼Œè¿”å›åŸå§‹çš„éƒ¨åˆ†ç»“æœ
                }
            }
        }

        Ok(response)
    }

    /// å°è¯•æ€»ç»“æ¨ç†fallover
    async fn try_summary_reasoning(
        &self,
        system_prompt: &str,
        user_prompt: &str,
        original_response: &ReActResponse,
    ) -> Result<ReActResponse> {
        let agent_builder = self.get_agent_builder();
        let agent_without_tools = agent_builder.build_agent_without_tools(system_prompt);

        let chat_history = original_response
            .chat_history
            .as_ref()
            .ok_or_else(|| anyhow::anyhow!("ç¼ºå°‘å¯¹è¯å†å²"))?;

        let summary_result = self
            .retry_with_backoff(|| async {
                SummaryReasoner::summarize_and_reason(
                    &agent_without_tools,
                    system_prompt,
                    user_prompt,
                    chat_history,
                    &original_response.tool_calls_history,
                )
                .await
            })
            .await?;

        Ok(ReActResponse::from_summary_reasoning(
            summary_result,
            original_response.iterations_used,
            original_response.tool_calls_history.clone(),
            chat_history.clone(),
        ))
    }

    /// ç®€åŒ–çš„å•è½®å¯¹è¯æ–¹æ³•ï¼ˆä¸ä½¿ç”¨å·¥å…·ï¼‰
    pub async fn prompt_without_react(
        &self,
        system_prompt: &str,
        user_prompt: &str,
    ) -> Result<String> {
        let agent_builder = self.get_agent_builder();
        let agent = agent_builder.build_agent_without_tools(system_prompt);

        self.retry_with_backoff(|| async { agent.prompt(user_prompt).await })
            .await
    }
}
